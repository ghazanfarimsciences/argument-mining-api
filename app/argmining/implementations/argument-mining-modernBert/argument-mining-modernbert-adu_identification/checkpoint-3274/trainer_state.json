{
  "best_global_step": 3274,
  "best_metric": 1.0,
  "best_model_checkpoint": "./argument-mining-modernbert-adu_identification\\checkpoint-3274",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 3274,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006108735491753207,
      "grad_norm": 12.400099754333496,
      "learning_rate": 3.865717192268566e-07,
      "loss": 1.1983,
      "step": 20
    },
    {
      "epoch": 0.012217470983506415,
      "grad_norm": 14.308473587036133,
      "learning_rate": 7.934893184130214e-07,
      "loss": 1.1874,
      "step": 40
    },
    {
      "epoch": 0.01832620647525962,
      "grad_norm": 12.326553344726562,
      "learning_rate": 1.2004069175991862e-06,
      "loss": 1.1383,
      "step": 60
    },
    {
      "epoch": 0.02443494196701283,
      "grad_norm": 11.782937049865723,
      "learning_rate": 1.607324516785351e-06,
      "loss": 1.0849,
      "step": 80
    },
    {
      "epoch": 0.030543677458766034,
      "grad_norm": 12.999295234680176,
      "learning_rate": 2.014242115971516e-06,
      "loss": 1.0439,
      "step": 100
    },
    {
      "epoch": 0.03665241295051924,
      "grad_norm": 11.541770935058594,
      "learning_rate": 2.4211597151576806e-06,
      "loss": 0.9775,
      "step": 120
    },
    {
      "epoch": 0.04276114844227245,
      "grad_norm": 9.196444511413574,
      "learning_rate": 2.8280773143438456e-06,
      "loss": 0.8497,
      "step": 140
    },
    {
      "epoch": 0.04886988393402566,
      "grad_norm": 8.635388374328613,
      "learning_rate": 3.23499491353001e-06,
      "loss": 0.779,
      "step": 160
    },
    {
      "epoch": 0.05497861942577886,
      "grad_norm": 7.723322868347168,
      "learning_rate": 3.641912512716175e-06,
      "loss": 0.6315,
      "step": 180
    },
    {
      "epoch": 0.06108735491753207,
      "grad_norm": 6.094361782073975,
      "learning_rate": 4.04883011190234e-06,
      "loss": 0.5093,
      "step": 200
    },
    {
      "epoch": 0.06719609040928527,
      "grad_norm": 4.093105316162109,
      "learning_rate": 4.455747711088505e-06,
      "loss": 0.3645,
      "step": 220
    },
    {
      "epoch": 0.07330482590103848,
      "grad_norm": 5.230907440185547,
      "learning_rate": 4.86266531027467e-06,
      "loss": 0.2473,
      "step": 240
    },
    {
      "epoch": 0.0794135613927917,
      "grad_norm": 1.3543790578842163,
      "learning_rate": 5.269582909460834e-06,
      "loss": 0.1409,
      "step": 260
    },
    {
      "epoch": 0.0855222968845449,
      "grad_norm": 0.7053036689758301,
      "learning_rate": 5.676500508647e-06,
      "loss": 0.07,
      "step": 280
    },
    {
      "epoch": 0.0916310323762981,
      "grad_norm": 0.3687954843044281,
      "learning_rate": 6.083418107833164e-06,
      "loss": 0.0271,
      "step": 300
    },
    {
      "epoch": 0.09773976786805132,
      "grad_norm": 0.3286372423171997,
      "learning_rate": 6.49033570701933e-06,
      "loss": 0.0129,
      "step": 320
    },
    {
      "epoch": 0.10384850335980451,
      "grad_norm": 0.1509452611207962,
      "learning_rate": 6.897253306205493e-06,
      "loss": 0.0062,
      "step": 340
    },
    {
      "epoch": 0.10995723885155773,
      "grad_norm": 0.12735070288181305,
      "learning_rate": 7.304170905391659e-06,
      "loss": 0.0037,
      "step": 360
    },
    {
      "epoch": 0.11606597434331094,
      "grad_norm": 0.1037168949842453,
      "learning_rate": 7.711088504577823e-06,
      "loss": 0.0022,
      "step": 380
    },
    {
      "epoch": 0.12217470983506414,
      "grad_norm": 0.051938246935606,
      "learning_rate": 8.11800610376399e-06,
      "loss": 0.0018,
      "step": 400
    },
    {
      "epoch": 0.12828344532681735,
      "grad_norm": 0.013138577342033386,
      "learning_rate": 8.524923702950153e-06,
      "loss": 0.0011,
      "step": 420
    },
    {
      "epoch": 0.13439218081857054,
      "grad_norm": 0.030213352292776108,
      "learning_rate": 8.931841302136319e-06,
      "loss": 0.001,
      "step": 440
    },
    {
      "epoch": 0.14050091631032377,
      "grad_norm": 0.027091749012470245,
      "learning_rate": 9.338758901322483e-06,
      "loss": 0.0007,
      "step": 460
    },
    {
      "epoch": 0.14660965180207697,
      "grad_norm": 0.02844395861029625,
      "learning_rate": 9.745676500508648e-06,
      "loss": 0.0006,
      "step": 480
    },
    {
      "epoch": 0.15271838729383017,
      "grad_norm": 0.006842598784714937,
      "learning_rate": 1.0152594099694813e-05,
      "loss": 0.0004,
      "step": 500
    },
    {
      "epoch": 0.1588271227855834,
      "grad_norm": 0.01850876212120056,
      "learning_rate": 1.0559511698880977e-05,
      "loss": 0.0004,
      "step": 520
    },
    {
      "epoch": 0.1649358582773366,
      "grad_norm": 0.12056729942560196,
      "learning_rate": 1.0966429298067143e-05,
      "loss": 0.0003,
      "step": 540
    },
    {
      "epoch": 0.1710445937690898,
      "grad_norm": 0.0048512909561395645,
      "learning_rate": 1.1373346897253308e-05,
      "loss": 0.0003,
      "step": 560
    },
    {
      "epoch": 0.177153329260843,
      "grad_norm": 0.01749168336391449,
      "learning_rate": 1.1780264496439473e-05,
      "loss": 0.0001,
      "step": 580
    },
    {
      "epoch": 0.1832620647525962,
      "grad_norm": 0.004617692437022924,
      "learning_rate": 1.2187182095625635e-05,
      "loss": 0.0001,
      "step": 600
    },
    {
      "epoch": 0.1893708002443494,
      "grad_norm": 0.010266737081110477,
      "learning_rate": 1.2594099694811802e-05,
      "loss": 0.0001,
      "step": 620
    },
    {
      "epoch": 0.19547953573610263,
      "grad_norm": 0.0029685497283935547,
      "learning_rate": 1.3001017293997966e-05,
      "loss": 0.0002,
      "step": 640
    },
    {
      "epoch": 0.20158827122785583,
      "grad_norm": 0.0070951529778540134,
      "learning_rate": 1.340793489318413e-05,
      "loss": 0.0001,
      "step": 660
    },
    {
      "epoch": 0.20769700671960903,
      "grad_norm": 0.0006093500996939838,
      "learning_rate": 1.3814852492370297e-05,
      "loss": 0.0001,
      "step": 680
    },
    {
      "epoch": 0.21380574221136225,
      "grad_norm": 0.0027916713152080774,
      "learning_rate": 1.4221770091556462e-05,
      "loss": 0.0001,
      "step": 700
    },
    {
      "epoch": 0.21991447770311545,
      "grad_norm": 0.0031972257420420647,
      "learning_rate": 1.4628687690742626e-05,
      "loss": 0.0001,
      "step": 720
    },
    {
      "epoch": 0.22602321319486865,
      "grad_norm": 0.005021069198846817,
      "learning_rate": 1.5035605289928789e-05,
      "loss": 0.0001,
      "step": 740
    },
    {
      "epoch": 0.23213194868662188,
      "grad_norm": 0.0006609234842471778,
      "learning_rate": 1.5442522889114954e-05,
      "loss": 0.0001,
      "step": 760
    },
    {
      "epoch": 0.23824068417837507,
      "grad_norm": 0.001981377135962248,
      "learning_rate": 1.5849440488301118e-05,
      "loss": 0.0,
      "step": 780
    },
    {
      "epoch": 0.24434941967012827,
      "grad_norm": 0.00039499570266343653,
      "learning_rate": 1.6256358087487286e-05,
      "loss": 0.0001,
      "step": 800
    },
    {
      "epoch": 0.25045815516188147,
      "grad_norm": 0.003763243556022644,
      "learning_rate": 1.666327568667345e-05,
      "loss": 0.0,
      "step": 820
    },
    {
      "epoch": 0.2565668906536347,
      "grad_norm": 0.0009041662560775876,
      "learning_rate": 1.7070193285859615e-05,
      "loss": 0.0,
      "step": 840
    },
    {
      "epoch": 0.2626756261453879,
      "grad_norm": 0.0002219624147983268,
      "learning_rate": 1.747711088504578e-05,
      "loss": 0.0001,
      "step": 860
    },
    {
      "epoch": 0.2687843616371411,
      "grad_norm": 0.001611029845662415,
      "learning_rate": 1.7884028484231945e-05,
      "loss": 0.0,
      "step": 880
    },
    {
      "epoch": 0.2748930971288943,
      "grad_norm": 0.00015967051149345934,
      "learning_rate": 1.829094608341811e-05,
      "loss": 0.0,
      "step": 900
    },
    {
      "epoch": 0.28100183262064754,
      "grad_norm": 0.0057272412814199924,
      "learning_rate": 1.8697863682604274e-05,
      "loss": 0.0,
      "step": 920
    },
    {
      "epoch": 0.2871105681124007,
      "grad_norm": 0.0006666608387604356,
      "learning_rate": 1.9104781281790438e-05,
      "loss": 0.0,
      "step": 940
    },
    {
      "epoch": 0.29321930360415394,
      "grad_norm": 0.020704733207821846,
      "learning_rate": 1.9511698880976603e-05,
      "loss": 0.0,
      "step": 960
    },
    {
      "epoch": 0.29932803909590716,
      "grad_norm": 0.0006177315954118967,
      "learning_rate": 1.9918616480162767e-05,
      "loss": 0.0,
      "step": 980
    },
    {
      "epoch": 0.30543677458766033,
      "grad_norm": 0.001629187143407762,
      "learning_rate": 1.9963796809593846e-05,
      "loss": 0.0,
      "step": 1000
    },
    {
      "epoch": 0.31154551007941356,
      "grad_norm": 0.000658574397675693,
      "learning_rate": 1.9918542821586154e-05,
      "loss": 0.0,
      "step": 1020
    },
    {
      "epoch": 0.3176542455711668,
      "grad_norm": 0.0003205707762390375,
      "learning_rate": 1.987328883357846e-05,
      "loss": 0.0,
      "step": 1040
    },
    {
      "epoch": 0.32376298106291995,
      "grad_norm": 0.00551701569929719,
      "learning_rate": 1.982803484557077e-05,
      "loss": 0.0,
      "step": 1060
    },
    {
      "epoch": 0.3298717165546732,
      "grad_norm": 0.0003404159506317228,
      "learning_rate": 1.9782780857563076e-05,
      "loss": 0.0,
      "step": 1080
    },
    {
      "epoch": 0.3359804520464264,
      "grad_norm": 0.00032207000185735524,
      "learning_rate": 1.973752686955538e-05,
      "loss": 0.0,
      "step": 1100
    },
    {
      "epoch": 0.3420891875381796,
      "grad_norm": 0.0008175582624971867,
      "learning_rate": 1.9692272881547688e-05,
      "loss": 0.0,
      "step": 1120
    },
    {
      "epoch": 0.3481979230299328,
      "grad_norm": 0.00031801010482013226,
      "learning_rate": 1.9647018893539995e-05,
      "loss": 0.0,
      "step": 1140
    },
    {
      "epoch": 0.354306658521686,
      "grad_norm": 0.00041021895594894886,
      "learning_rate": 1.9601764905532303e-05,
      "loss": 0.0,
      "step": 1160
    },
    {
      "epoch": 0.3604153940134392,
      "grad_norm": 0.0006005713366903365,
      "learning_rate": 1.955651091752461e-05,
      "loss": 0.0052,
      "step": 1180
    },
    {
      "epoch": 0.3665241295051924,
      "grad_norm": 0.00041950560989789665,
      "learning_rate": 1.9511256929516914e-05,
      "loss": 0.0,
      "step": 1200
    },
    {
      "epoch": 0.37263286499694565,
      "grad_norm": 0.006403460167348385,
      "learning_rate": 1.9466002941509222e-05,
      "loss": 0.0,
      "step": 1220
    },
    {
      "epoch": 0.3787416004886988,
      "grad_norm": 0.0007222584099508822,
      "learning_rate": 1.942074895350153e-05,
      "loss": 0.0,
      "step": 1240
    },
    {
      "epoch": 0.38485033598045204,
      "grad_norm": 0.0009637826005928218,
      "learning_rate": 1.9375494965493837e-05,
      "loss": 0.0,
      "step": 1260
    },
    {
      "epoch": 0.39095907147220527,
      "grad_norm": 0.0003178020706400275,
      "learning_rate": 1.9330240977486144e-05,
      "loss": 0.0,
      "step": 1280
    },
    {
      "epoch": 0.39706780696395844,
      "grad_norm": 3.7188503483776e-05,
      "learning_rate": 1.928498698947845e-05,
      "loss": 0.0,
      "step": 1300
    },
    {
      "epoch": 0.40317654245571166,
      "grad_norm": 0.0003238545614294708,
      "learning_rate": 1.9239733001470756e-05,
      "loss": 0.0,
      "step": 1320
    },
    {
      "epoch": 0.4092852779474649,
      "grad_norm": 5.091378261568025e-05,
      "learning_rate": 1.9194479013463063e-05,
      "loss": 0.0,
      "step": 1340
    },
    {
      "epoch": 0.41539401343921806,
      "grad_norm": 0.00042147512431256473,
      "learning_rate": 1.9149225025455367e-05,
      "loss": 0.0,
      "step": 1360
    },
    {
      "epoch": 0.4215027489309713,
      "grad_norm": 6.151907291496173e-05,
      "learning_rate": 1.910397103744768e-05,
      "loss": 0.0,
      "step": 1380
    },
    {
      "epoch": 0.4276114844227245,
      "grad_norm": 0.0014860967639833689,
      "learning_rate": 1.9058717049439982e-05,
      "loss": 0.0,
      "step": 1400
    },
    {
      "epoch": 0.4337202199144777,
      "grad_norm": 0.00029171057394705713,
      "learning_rate": 1.901346306143229e-05,
      "loss": 0.0,
      "step": 1420
    },
    {
      "epoch": 0.4398289554062309,
      "grad_norm": 2.3368038455373608e-05,
      "learning_rate": 1.8968209073424597e-05,
      "loss": 0.0,
      "step": 1440
    },
    {
      "epoch": 0.44593769089798413,
      "grad_norm": 0.00016489721019752324,
      "learning_rate": 1.89229550854169e-05,
      "loss": 0.0,
      "step": 1460
    },
    {
      "epoch": 0.4520464263897373,
      "grad_norm": 8.190864900825545e-05,
      "learning_rate": 1.8877701097409212e-05,
      "loss": 0.0,
      "step": 1480
    },
    {
      "epoch": 0.4581551618814905,
      "grad_norm": 0.00023953942582011223,
      "learning_rate": 1.8832447109401516e-05,
      "loss": 0.0,
      "step": 1500
    },
    {
      "epoch": 0.46426389737324375,
      "grad_norm": 6.830177153460681e-05,
      "learning_rate": 1.8787193121393824e-05,
      "loss": 0.0,
      "step": 1520
    },
    {
      "epoch": 0.4703726328649969,
      "grad_norm": 0.0006577755557373166,
      "learning_rate": 1.874193913338613e-05,
      "loss": 0.0,
      "step": 1540
    },
    {
      "epoch": 0.47648136835675015,
      "grad_norm": 3.985461080446839e-05,
      "learning_rate": 1.8696685145378436e-05,
      "loss": 0.0,
      "step": 1560
    },
    {
      "epoch": 0.48259010384850337,
      "grad_norm": 0.0002218626468675211,
      "learning_rate": 1.8651431157370746e-05,
      "loss": 0.0,
      "step": 1580
    },
    {
      "epoch": 0.48869883934025654,
      "grad_norm": 0.0001651157799642533,
      "learning_rate": 1.860617716936305e-05,
      "loss": 0.0,
      "step": 1600
    },
    {
      "epoch": 0.49480757483200977,
      "grad_norm": 0.0006914675468578935,
      "learning_rate": 1.8560923181355358e-05,
      "loss": 0.0,
      "step": 1620
    },
    {
      "epoch": 0.5009163103237629,
      "grad_norm": 1.723111745377537e-05,
      "learning_rate": 1.8515669193347665e-05,
      "loss": 0.0,
      "step": 1640
    },
    {
      "epoch": 0.5070250458155162,
      "grad_norm": 0.0008821169612929225,
      "learning_rate": 1.847041520533997e-05,
      "loss": 0.0,
      "step": 1660
    },
    {
      "epoch": 0.5131337813072694,
      "grad_norm": 6.577936437679455e-05,
      "learning_rate": 1.842516121733228e-05,
      "loss": 0.0,
      "step": 1680
    },
    {
      "epoch": 0.5192425167990226,
      "grad_norm": 0.0009626816608943045,
      "learning_rate": 1.8379907229324585e-05,
      "loss": 0.0,
      "step": 1700
    },
    {
      "epoch": 0.5253512522907758,
      "grad_norm": 2.2510850612889044e-05,
      "learning_rate": 1.8334653241316892e-05,
      "loss": 0.0,
      "step": 1720
    },
    {
      "epoch": 0.531459987782529,
      "grad_norm": 0.0002145500766346231,
      "learning_rate": 1.82893992533092e-05,
      "loss": 0.0,
      "step": 1740
    },
    {
      "epoch": 0.5375687232742822,
      "grad_norm": 0.0003642650553956628,
      "learning_rate": 1.8244145265301507e-05,
      "loss": 0.0,
      "step": 1760
    },
    {
      "epoch": 0.5436774587660355,
      "grad_norm": 4.919306593365036e-05,
      "learning_rate": 1.8198891277293815e-05,
      "loss": 0.0,
      "step": 1780
    },
    {
      "epoch": 0.5497861942577886,
      "grad_norm": 0.0002395156625425443,
      "learning_rate": 1.815363728928612e-05,
      "loss": 0.0,
      "step": 1800
    },
    {
      "epoch": 0.5558949297495418,
      "grad_norm": 2.8957907488802448e-05,
      "learning_rate": 1.8108383301278426e-05,
      "loss": 0.0,
      "step": 1820
    },
    {
      "epoch": 0.5620036652412951,
      "grad_norm": 0.00022055547742638737,
      "learning_rate": 1.8063129313270734e-05,
      "loss": 0.0,
      "step": 1840
    },
    {
      "epoch": 0.5681124007330483,
      "grad_norm": 0.00018589374667499214,
      "learning_rate": 1.801787532526304e-05,
      "loss": 0.0,
      "step": 1860
    },
    {
      "epoch": 0.5742211362248014,
      "grad_norm": 0.00023473000328522176,
      "learning_rate": 1.797262133725535e-05,
      "loss": 0.0,
      "step": 1880
    },
    {
      "epoch": 0.5803298717165547,
      "grad_norm": 2.8126758479629643e-05,
      "learning_rate": 1.7927367349247653e-05,
      "loss": 0.0,
      "step": 1900
    },
    {
      "epoch": 0.5864386072083079,
      "grad_norm": 5.03895862493664e-05,
      "learning_rate": 1.788211336123996e-05,
      "loss": 0.0,
      "step": 1920
    },
    {
      "epoch": 0.592547342700061,
      "grad_norm": 7.964979886310175e-05,
      "learning_rate": 1.7836859373232268e-05,
      "loss": 0.0,
      "step": 1940
    },
    {
      "epoch": 0.5986560781918143,
      "grad_norm": 8.680385508341715e-05,
      "learning_rate": 1.7791605385224575e-05,
      "loss": 0.0,
      "step": 1960
    },
    {
      "epoch": 0.6047648136835675,
      "grad_norm": 0.012063160538673401,
      "learning_rate": 1.7746351397216883e-05,
      "loss": 0.0,
      "step": 1980
    },
    {
      "epoch": 0.6108735491753207,
      "grad_norm": 2.5256067601731047e-05,
      "learning_rate": 1.7701097409209187e-05,
      "loss": 0.0,
      "step": 2000
    },
    {
      "epoch": 0.6169822846670739,
      "grad_norm": 1.4461365026363637e-05,
      "learning_rate": 1.7655843421201494e-05,
      "loss": 0.0,
      "step": 2020
    },
    {
      "epoch": 0.6230910201588271,
      "grad_norm": 0.0003046123601961881,
      "learning_rate": 1.76105894331938e-05,
      "loss": 0.0,
      "step": 2040
    },
    {
      "epoch": 0.6291997556505803,
      "grad_norm": 4.016573075205088e-05,
      "learning_rate": 1.756533544518611e-05,
      "loss": 0.0,
      "step": 2060
    },
    {
      "epoch": 0.6353084911423336,
      "grad_norm": 2.9901688321842812e-05,
      "learning_rate": 1.7520081457178417e-05,
      "loss": 0.0,
      "step": 2080
    },
    {
      "epoch": 0.6414172266340867,
      "grad_norm": 0.00047802471090108156,
      "learning_rate": 1.7474827469170724e-05,
      "loss": 0.0012,
      "step": 2100
    },
    {
      "epoch": 0.6475259621258399,
      "grad_norm": 6.06982757744845e-05,
      "learning_rate": 1.7429573481163028e-05,
      "loss": 0.0,
      "step": 2120
    },
    {
      "epoch": 0.6536346976175932,
      "grad_norm": 1.9158838767907582e-05,
      "learning_rate": 1.7384319493155336e-05,
      "loss": 0.0,
      "step": 2140
    },
    {
      "epoch": 0.6597434331093464,
      "grad_norm": 6.452037723647663e-06,
      "learning_rate": 1.7339065505147643e-05,
      "loss": 0.0,
      "step": 2160
    },
    {
      "epoch": 0.6658521686010995,
      "grad_norm": 7.17880466254428e-05,
      "learning_rate": 1.729381151713995e-05,
      "loss": 0.0,
      "step": 2180
    },
    {
      "epoch": 0.6719609040928528,
      "grad_norm": 0.0032405073288828135,
      "learning_rate": 1.7248557529132258e-05,
      "loss": 0.0,
      "step": 2200
    },
    {
      "epoch": 0.678069639584606,
      "grad_norm": 5.5683343816781417e-05,
      "learning_rate": 1.7203303541124562e-05,
      "loss": 0.0,
      "step": 2220
    },
    {
      "epoch": 0.6841783750763591,
      "grad_norm": 3.769348040805198e-05,
      "learning_rate": 1.715804955311687e-05,
      "loss": 0.0,
      "step": 2240
    },
    {
      "epoch": 0.6902871105681124,
      "grad_norm": 5.3633768402505666e-05,
      "learning_rate": 1.7112795565109177e-05,
      "loss": 0.0,
      "step": 2260
    },
    {
      "epoch": 0.6963958460598656,
      "grad_norm": 0.003320802003145218,
      "learning_rate": 1.706754157710148e-05,
      "loss": 0.0,
      "step": 2280
    },
    {
      "epoch": 0.7025045815516188,
      "grad_norm": 9.956937719834968e-05,
      "learning_rate": 1.7022287589093792e-05,
      "loss": 0.0,
      "step": 2300
    },
    {
      "epoch": 0.708613317043372,
      "grad_norm": 0.00021457357797771692,
      "learning_rate": 1.6977033601086096e-05,
      "loss": 0.0,
      "step": 2320
    },
    {
      "epoch": 0.7147220525351252,
      "grad_norm": 2.2512729628942907e-05,
      "learning_rate": 1.6931779613078404e-05,
      "loss": 0.0,
      "step": 2340
    },
    {
      "epoch": 0.7208307880268784,
      "grad_norm": 1.588170744071249e-05,
      "learning_rate": 1.688652562507071e-05,
      "loss": 0.0,
      "step": 2360
    },
    {
      "epoch": 0.7269395235186317,
      "grad_norm": 0.0002954806259367615,
      "learning_rate": 1.6841271637063015e-05,
      "loss": 0.0,
      "step": 2380
    },
    {
      "epoch": 0.7330482590103848,
      "grad_norm": 0.001866354956291616,
      "learning_rate": 1.6796017649055326e-05,
      "loss": 0.0,
      "step": 2400
    },
    {
      "epoch": 0.739156994502138,
      "grad_norm": 0.00017774761363398284,
      "learning_rate": 1.675076366104763e-05,
      "loss": 0.0,
      "step": 2420
    },
    {
      "epoch": 0.7452657299938913,
      "grad_norm": 1.3824997949996032e-05,
      "learning_rate": 1.6705509673039938e-05,
      "loss": 0.0,
      "step": 2440
    },
    {
      "epoch": 0.7513744654856445,
      "grad_norm": 1.403527130605653e-05,
      "learning_rate": 1.6660255685032245e-05,
      "loss": 0.0,
      "step": 2460
    },
    {
      "epoch": 0.7574832009773976,
      "grad_norm": 7.78220419306308e-05,
      "learning_rate": 1.661500169702455e-05,
      "loss": 0.0,
      "step": 2480
    },
    {
      "epoch": 0.7635919364691509,
      "grad_norm": 0.0004524637770373374,
      "learning_rate": 1.656974770901686e-05,
      "loss": 0.0,
      "step": 2500
    },
    {
      "epoch": 0.7697006719609041,
      "grad_norm": 3.276535790064372e-05,
      "learning_rate": 1.6524493721009164e-05,
      "loss": 0.0,
      "step": 2520
    },
    {
      "epoch": 0.7758094074526573,
      "grad_norm": 0.0006202255608513951,
      "learning_rate": 1.6479239733001472e-05,
      "loss": 0.0,
      "step": 2540
    },
    {
      "epoch": 0.7819181429444105,
      "grad_norm": 2.3161508579505607e-05,
      "learning_rate": 1.643398574499378e-05,
      "loss": 0.0,
      "step": 2560
    },
    {
      "epoch": 0.7880268784361637,
      "grad_norm": 8.531838830094784e-06,
      "learning_rate": 1.6388731756986083e-05,
      "loss": 0.0,
      "step": 2580
    },
    {
      "epoch": 0.7941356139279169,
      "grad_norm": 2.592803502921015e-05,
      "learning_rate": 1.6343477768978394e-05,
      "loss": 0.0,
      "step": 2600
    },
    {
      "epoch": 0.8002443494196702,
      "grad_norm": 4.683095176005736e-05,
      "learning_rate": 1.62982237809707e-05,
      "loss": 0.0,
      "step": 2620
    },
    {
      "epoch": 0.8063530849114233,
      "grad_norm": 3.9714359445497394e-05,
      "learning_rate": 1.6252969792963006e-05,
      "loss": 0.0,
      "step": 2640
    },
    {
      "epoch": 0.8124618204031765,
      "grad_norm": 4.0372367948293686e-05,
      "learning_rate": 1.6207715804955313e-05,
      "loss": 0.0,
      "step": 2660
    },
    {
      "epoch": 0.8185705558949298,
      "grad_norm": 0.000146931255585514,
      "learning_rate": 1.6162461816947618e-05,
      "loss": 0.0,
      "step": 2680
    },
    {
      "epoch": 0.8246792913866829,
      "grad_norm": 3.735457357834093e-05,
      "learning_rate": 1.611720782893993e-05,
      "loss": 0.0,
      "step": 2700
    },
    {
      "epoch": 0.8307880268784361,
      "grad_norm": 0.0001235521922353655,
      "learning_rate": 1.6071953840932232e-05,
      "loss": 0.0,
      "step": 2720
    },
    {
      "epoch": 0.8368967623701894,
      "grad_norm": 5.373641670303186e-06,
      "learning_rate": 1.602669985292454e-05,
      "loss": 0.0,
      "step": 2740
    },
    {
      "epoch": 0.8430054978619426,
      "grad_norm": 2.2614691260969266e-05,
      "learning_rate": 1.5981445864916847e-05,
      "loss": 0.0,
      "step": 2760
    },
    {
      "epoch": 0.8491142333536957,
      "grad_norm": 8.23852406028891e-06,
      "learning_rate": 1.593619187690915e-05,
      "loss": 0.0,
      "step": 2780
    },
    {
      "epoch": 0.855222968845449,
      "grad_norm": 2.084010156977456e-05,
      "learning_rate": 1.5890937888901462e-05,
      "loss": 0.0,
      "step": 2800
    },
    {
      "epoch": 0.8613317043372022,
      "grad_norm": 0.00022606820857618004,
      "learning_rate": 1.5845683900893767e-05,
      "loss": 0.0,
      "step": 2820
    },
    {
      "epoch": 0.8674404398289554,
      "grad_norm": 6.42108716419898e-05,
      "learning_rate": 1.5800429912886074e-05,
      "loss": 0.0,
      "step": 2840
    },
    {
      "epoch": 0.8735491753207086,
      "grad_norm": 0.00010934592137346044,
      "learning_rate": 1.575517592487838e-05,
      "loss": 0.0,
      "step": 2860
    },
    {
      "epoch": 0.8796579108124618,
      "grad_norm": 5.4220166930463165e-05,
      "learning_rate": 1.570992193687069e-05,
      "loss": 0.0,
      "step": 2880
    },
    {
      "epoch": 0.885766646304215,
      "grad_norm": 0.00011957731476286426,
      "learning_rate": 1.5664667948862996e-05,
      "loss": 0.0,
      "step": 2900
    },
    {
      "epoch": 0.8918753817959683,
      "grad_norm": 4.480610368773341e-05,
      "learning_rate": 1.56194139608553e-05,
      "loss": 0.0,
      "step": 2920
    },
    {
      "epoch": 0.8979841172877214,
      "grad_norm": 4.549277491605608e-06,
      "learning_rate": 1.5574159972847608e-05,
      "loss": 0.0,
      "step": 2940
    },
    {
      "epoch": 0.9040928527794746,
      "grad_norm": 0.0005228703957982361,
      "learning_rate": 1.5528905984839916e-05,
      "loss": 0.0,
      "step": 2960
    },
    {
      "epoch": 0.9102015882712279,
      "grad_norm": 2.7460104320198298e-05,
      "learning_rate": 1.5483651996832223e-05,
      "loss": 0.0,
      "step": 2980
    },
    {
      "epoch": 0.916310323762981,
      "grad_norm": 9.633360605221242e-06,
      "learning_rate": 1.543839800882453e-05,
      "loss": 0.0,
      "step": 3000
    },
    {
      "epoch": 0.9224190592547342,
      "grad_norm": 5.38237982254941e-05,
      "learning_rate": 1.5393144020816835e-05,
      "loss": 0.0,
      "step": 3020
    },
    {
      "epoch": 0.9285277947464875,
      "grad_norm": 3.3436510420870036e-05,
      "learning_rate": 1.5347890032809142e-05,
      "loss": 0.0,
      "step": 3040
    },
    {
      "epoch": 0.9346365302382407,
      "grad_norm": 3.667506462079473e-05,
      "learning_rate": 1.530263604480145e-05,
      "loss": 0.0,
      "step": 3060
    },
    {
      "epoch": 0.9407452657299938,
      "grad_norm": 0.000111857705633156,
      "learning_rate": 1.5257382056793757e-05,
      "loss": 0.0,
      "step": 3080
    },
    {
      "epoch": 0.9468540012217471,
      "grad_norm": 6.155701157695148e-06,
      "learning_rate": 1.5212128068786063e-05,
      "loss": 0.0,
      "step": 3100
    },
    {
      "epoch": 0.9529627367135003,
      "grad_norm": 0.0005919108516536653,
      "learning_rate": 1.5166874080778369e-05,
      "loss": 0.0,
      "step": 3120
    },
    {
      "epoch": 0.9590714722052535,
      "grad_norm": 2.2690450350637548e-05,
      "learning_rate": 1.5121620092770676e-05,
      "loss": 0.0,
      "step": 3140
    },
    {
      "epoch": 0.9651802076970067,
      "grad_norm": 6.0387043049559e-05,
      "learning_rate": 1.5076366104762984e-05,
      "loss": 0.0,
      "step": 3160
    },
    {
      "epoch": 0.9712889431887599,
      "grad_norm": 9.73990245256573e-05,
      "learning_rate": 1.5031112116755291e-05,
      "loss": 0.0,
      "step": 3180
    },
    {
      "epoch": 0.9773976786805131,
      "grad_norm": 8.816643094178289e-05,
      "learning_rate": 1.4985858128747597e-05,
      "loss": 0.0,
      "step": 3200
    },
    {
      "epoch": 0.9835064141722664,
      "grad_norm": 1.3019060133956373e-05,
      "learning_rate": 1.4940604140739904e-05,
      "loss": 0.0,
      "step": 3220
    },
    {
      "epoch": 0.9896151496640195,
      "grad_norm": 1.3225118891568854e-05,
      "learning_rate": 1.489535015273221e-05,
      "loss": 0.0,
      "step": 3240
    },
    {
      "epoch": 0.9957238851557727,
      "grad_norm": 2.3799893824616447e-05,
      "learning_rate": 1.4850096164724516e-05,
      "loss": 0.0,
      "step": 3260
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 1.0,
      "eval_loss": 1.1455601907073287e-06,
      "eval_runtime": 221.1464,
      "eval_samples_per_second": 59.219,
      "eval_steps_per_second": 7.402,
      "step": 3274
    }
  ],
  "logging_steps": 20,
  "max_steps": 9822,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.812101928984576e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
